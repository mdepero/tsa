{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get imports and initialize matplotlib..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "from collections import OrderedDict\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import math\n",
    "import os\n",
    "import sys\n",
    "\n",
    "%pylab inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get metadata from csv file..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ps = 16 # num of perspectives\n",
    "zs = 18 # num of outputs zones\n",
    "\n",
    "ids = []\n",
    "targets = OrderedDict()\n",
    "with open('labels.csv') as f:\n",
    "    header = f.readline()\n",
    "    for line in f:\n",
    "        idzone, label = line.split(',')\n",
    "        sampleid, zone = idzone.split('_')\n",
    "        zone_number = int(zone[len('Zone'):]) # string looks like \"Zone8\" so this chops off \"Zone\"\n",
    "#         zone_number -= 1\n",
    "        \n",
    "        if sampleid not in targets:\n",
    "            ids.append(sampleid)\n",
    "            targets[sampleid] = np.zeros(zs)\n",
    "        targets[sampleid][zone_number] = float(label)\n",
    "\n",
    "random.shuffle(ids) # add randomness to list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create our (giant...) matrices for training. Takes up roughly 12 GB of system memory (thankfully mine as 32)\n",
    "\n",
    "Set n to a value to reduce this size for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50, 8192, 660)\n",
      "(50, 18)\n"
     ]
    }
   ],
   "source": [
    "X_train = [] # training data\n",
    "y_train = [] # training one hot labels\n",
    "l_train = [] # training labels\n",
    "\n",
    "w = 512 * ps\n",
    "h = 660\n",
    "\n",
    "\n",
    "i = 0\n",
    "n = 50#len(ids)\n",
    "\n",
    "for sid in ids:\n",
    "    path = 'data/{}.aps.npz'.format(sid)\n",
    "\n",
    "    npzfile = np.load(path)\n",
    "    data = npzfile['arr_0']\n",
    "    \n",
    "    X_train.append(data)\n",
    "    l_train.append(np.argmax(targets[sid]))\n",
    "    if (np.argmax(targets[sid]) == 0):\n",
    "        targets[sid][0] = 1\n",
    "    y_train.append(targets[sid])\n",
    "    \n",
    "    i += 1\n",
    "    print (i, \"of\", n, end=\"\\r\")\n",
    "    if i >= n:\n",
    "        break\n",
    "\n",
    "X_train = np.moveaxis(X_train, 3, 1)\n",
    "y_train = np.moveaxis(y_train, 0, 0) # to convert into a matrix (vs a dictionary?)\n",
    "\n",
    "X_train = np.reshape(X_train, [n, w, h])\n",
    "X_train = X_train.astype(np.float32)\n",
    "print (np.shape(X_train))\n",
    "print (np.shape(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.  0.  0.] 3\n",
      "[ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.] 8\n",
      "[ 0.  0.  1.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.] 2\n",
      "[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.] 10\n",
      "[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.] 14\n",
      "[ 1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.] 0\n",
      "[ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.] 5\n",
      "[ 0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.] 6\n",
      "[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.] 17\n",
      "[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.] 14\n",
      "[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.] 15\n",
      "[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.] 15\n",
      "[ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.] 4\n",
      "[ 0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  0.  0.] 2\n",
      "[ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.] 3\n",
      "[ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.] 4\n",
      "[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.] 13\n",
      "[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  0.] 9\n",
      "[ 1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.] 0\n",
      "[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.] 13\n",
      "[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.] 9\n",
      "[ 1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.] 0\n",
      "[ 0.  0.  1.  0.  1.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.] 2\n",
      "[ 1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.] 0\n",
      "[ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.] 5\n",
      "[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.] 10\n",
      "[ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.] 7\n",
      "[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.] 13\n",
      "[ 1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.] 0\n",
      "[ 0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.] 3\n",
      "[ 1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.] 0\n",
      "[ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.] 6\n",
      "[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.] 16\n",
      "[ 1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.] 0\n",
      "[ 1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.] 0\n",
      "[ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.] 5\n",
      "[ 0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.] 4\n",
      "[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.] 15\n",
      "[ 0.  0.  0.  1.  0.  1.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.] 3\n",
      "[ 0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.] 3\n",
      "[ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.] 3\n",
      "[ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.] 7\n",
      "[ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.] 7\n",
      "[ 0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  0.  0.  0.  0.] 8\n",
      "[ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  0.  0.  1.] 8\n",
      "[ 1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.] 0\n",
      "[ 1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.] 0\n",
      "[ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.] 3\n",
      "[ 0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  0.  0.  0.  0.] 8\n",
      "[ 0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.] 5\n"
     ]
    }
   ],
   "source": [
    "for x in range(max(n,50)):\n",
    "    print (y_train[x], l_train[x])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For some reason the perspective is the last axis in the matrix, move it to be the second matrix so it's more logical (doesn't actually make a difference from a training perspective)\n",
    "\n",
    "X_train should now be in the form [sampleIndex, perspective, x, y]\n",
    "\n",
    "Also, moveaxis somehow does this operation while using zero extra memory, no idea how but clearly whoever made it had a better professor for algorithms than Gelfond"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print matrix..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " ..., \n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]]\n",
      "[ 0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.  0.  0.]\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "print (X_train[0]) # first sample\n",
    "print (y_train[0])\n",
    "print (l_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show Image..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from matplotlib.pyplot import imshow \n",
    "# figsize(15,4)\n",
    "# im = imshow(np.flipud(x_test[0,:,:]).T, cmap = 'viridis') # 1st sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "make .train() ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# model hyper parameters\n",
    "learning_rate = 0.0005\n",
    "\n",
    "def conv_layer(input_data, num_input_channels, num_filters, filter_shape, name):\n",
    "    # setup the filter input shape for tf.nn.conv_2d\n",
    "    conv_filt_shape = [filter_shape[0], filter_shape[1], num_input_channels,\n",
    "                      num_filters]\n",
    "\n",
    "    # initialise weights and bias for the filter\n",
    "    weights = tf.Variable(tf.truncated_normal(conv_filt_shape, stddev=0.03),\n",
    "                                      name=name+'_W')\n",
    "    bias = tf.Variable(tf.truncated_normal([num_filters]), name=name+'_b')\n",
    "\n",
    "    # setup the convolutional layer operation\n",
    "    out_layer = tf.nn.conv2d(input_data, weights, [1, 1, 1, 1], padding='SAME')\n",
    "\n",
    "    # add the bias\n",
    "    out_layer += bias\n",
    "\n",
    "    # apply a ReLU non-linear activation\n",
    "    out_layer = tf.nn.relu(out_layer)\n",
    "    return out_layer\n",
    "    \n",
    "def pool(out_layer, pool_shape):\n",
    "    # now perform max pooling\n",
    "    ksize = [1, pool_shape[0], pool_shape[1], 1]\n",
    "    strides = [1, 3, 2, 1]\n",
    "    out_layer = tf.nn.max_pool(out_layer, ksize=ksize, strides=strides, \n",
    "                               padding='VALID')\n",
    "    return out_layer\n",
    "\n",
    "\n",
    "x = tf.placeholder(tf.float32, [None, w, h], name=\"inputx\")\n",
    "\n",
    "x_shaped = tf.reshape(x, [-1, w, h, 1])\n",
    "# x_shaped = tf.cast(x_shaped, tf.float32)\n",
    "\n",
    "y = tf.placeholder(tf.float16, [None, zs])\n",
    "\n",
    "l1 = conv_layer(x_shaped, 1, 3, [3, 3], name='l1')\n",
    "l2 = conv_layer(l1, 3, 16, [3, 3], name='l2')\n",
    "l3 = pool(l2, [2,2])\n",
    "l4 = conv_layer(l3, 16, 16, [3, 3], name='l4')\n",
    "l5 = conv_layer(l4, 16, 16, [3, 3], name='l5')\n",
    "l6 = pool(l5, [2,2])\n",
    "l7 = conv_layer(l6, 16, 32, [3, 3], name='l7')\n",
    "l8 = conv_layer(l7, 32, 32, [3, 3], name='l8')\n",
    "l9 = conv_layer(l8, 32, 32, [3, 3], name='l9')\n",
    "l10 = pool(l9, [2,2])\n",
    "l11 = conv_layer(l10, 32, 32, [3, 3], name='l11')\n",
    "l12 = conv_layer(l11, 32, 32, [3, 3], name='l12')\n",
    "l13 = conv_layer(l12, 32, 32, [3, 3], name='l13')\n",
    "l14 = pool(l13, [2,2])\n",
    "l15 = conv_layer(l14, 32, 32, [3, 3], name='l15')\n",
    "l16 = conv_layer(l15, 32, 32, [3, 3], name='l16')\n",
    "l17 = conv_layer(l16, 32, 32, [3, 3], name='l17')\n",
    "l18 = pool(l17, [2,2])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#dilation, seperable filter\n",
    "\n",
    "dumb = 21760 # use shape_check to get this\n",
    "\n",
    "flattened = tf.reshape(l18, [-1, dumb])\n",
    "\n",
    "wd1 = tf.Variable(tf.truncated_normal([dumb, 1024], stddev=0.1), name='wd1')\n",
    "bd1 = tf.Variable(tf.truncated_normal([1024], stddev=0.01), name='bd1')\n",
    "dense_layer1 = tf.matmul(flattened, wd1) + bd1\n",
    "dense_layer1 = tf.nn.relu(dense_layer1)\n",
    "\n",
    "wd2 = tf.Variable(tf.truncated_normal([1024, 1024], stddev=0.1), name='wd2')\n",
    "bd2 = tf.Variable(tf.truncated_normal([1024], stddev=0.01), name='bd2')\n",
    "dense_layer2 = tf.matmul(dense_layer1, wd2) + bd2\n",
    "dense_layer2 = tf.nn.relu(dense_layer2)\n",
    "\n",
    "wd3 = tf.Variable(tf.truncated_normal([1024, zs], stddev=0.1), name='wd3')\n",
    "bd3 = tf.Variable(tf.truncated_normal([zs], stddev=0.01), name='bd3')\n",
    "dense_layer3 = tf.matmul(dense_layer2, wd3) + bd3\n",
    "dense_layer3 = tf.nn.relu(dense_layer3)\n",
    "\n",
    "y_ = tf.nn.softmax(dense_layer3)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "cross_entropy = tf.nn.softmax_cross_entropy_with_logits(logits=dense_layer3, labels=y)\n",
    "\n",
    "# z_weights = tf.constant([10000, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], tf.float32)\n",
    "\n",
    "# weighted_cross_entropy = tf.multiply(cross_entropy, z_weights)\n",
    "\n",
    "weighted_cross_entropy = tf.exp(tf.div(tf.constant(1.), tf.subtract(tf.constant(1.), cross_entropy)))\n",
    "\n",
    "cost = tf.reduce_mean(weighted_cross_entropy)\n",
    "\n",
    "\n",
    "# add an optimiser\n",
    "optimiser = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "\n",
    "# define an accuracy assessment operation\n",
    "correct_prediction = tf.equal(tf.argmax(y, 1), tf.argmax(y_, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float16))\n",
    "\n",
    "\n",
    "# with tf.Session() as sess:\n",
    "#     # initialise the variables\n",
    "#     sess.run(init_op)\n",
    "#     total_batch = int(len(y_train) / batch_size)\n",
    "#     for epoch in range(epochs):\n",
    "#         avg_cost = 0\n",
    "#         for i in range(total_batch):\n",
    "#             batch_x, batch_y = X_train[0][(total_batch*epoch+i):min(len(y_train),(total_batch*(epoch+1)))]\n",
    "#             _, c = sess.run([optimiser, cross_entropy], \n",
    "#                             feed_dict={x: batch_x, y: batch_y})\n",
    "#             avg_cost += c / total_batch\n",
    "#         test_acc = sess.run(accuracy, \n",
    "#                        feed_dict={x: mnist.test.images, y: mnist.test.labels})\n",
    "#         print(\"Epoch:\", (epoch + 1), \"cost =\", \"{:.3f}\".format(avg_cost), \" \n",
    "#                  test accuracy: {:.3f}\".format(test_acc))\n",
    "\n",
    "#     print(\"\\nTraining complete!\")\n",
    "#     print(sess.run(accuracy, feed_dict={x: mnist.test.images, y: mnist.test.labels}))\n",
    "\n",
    "shape_check = tf.shape(l18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with tf.Session() as sess:\n",
    "#     # initialise the variables\n",
    "#     init_op = tf.global_variables_initializer()\n",
    "#     sess.run(init_op)\n",
    "    \n",
    "#     print(sess.run(shape_check, feed_dict={x: X_train[0:1]}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "run .train() ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from D:\\ML\\chkpts\\VGG_12-08-v2\\checkpoint_0.ckpt\n",
      "Ran Batch  0  out of  17 \n",
      "Results:  [[ 0.05555556  0.05555556  0.05555556  0.05555556  0.05555556  0.05555556\n",
      "   0.05555556  0.05555556  0.05555556  0.05555556  0.05555556  0.05555556\n",
      "   0.05555556  0.05555556  0.05555556  0.05555556  0.05555556  0.05555556]\n",
      " [ 0.05555556  0.05555556  0.05555556  0.05555556  0.05555556  0.05555556\n",
      "   0.05555556  0.05555556  0.05555556  0.05555556  0.05555556  0.05555556\n",
      "   0.05555556  0.05555556  0.05555556  0.05555556  0.05555556  0.05555556]\n",
      " [ 0.05555556  0.05555556  0.05555556  0.05555556  0.05555556  0.05555556\n",
      "   0.05555556  0.05555556  0.05555556  0.05555556  0.05555556  0.05555556\n",
      "   0.05555556  0.05555556  0.05555556  0.05555556  0.05555556  0.05555556]] \n",
      "Labels:  [[ 0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.]\n",
      " [ 0.  0.  1.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.]]\n",
      "Ran Batch  1  out of  17 \n",
      "Results:  [[ 0.05555556  0.05555556  0.05555556  0.05555556  0.05555556  0.05555556\n",
      "   0.05555556  0.05555556  0.05555556  0.05555556  0.05555556  0.05555556\n",
      "   0.05555556  0.05555556  0.05555556  0.05555556  0.05555556  0.05555556]\n",
      " [ 0.05555556  0.05555556  0.05555556  0.05555556  0.05555556  0.05555556\n",
      "   0.05555556  0.05555556  0.05555556  0.05555556  0.05555556  0.05555556\n",
      "   0.05555556  0.05555556  0.05555556  0.05555556  0.05555556  0.05555556]\n",
      " [ 0.05555556  0.05555556  0.05555556  0.05555556  0.05555556  0.05555556\n",
      "   0.05555556  0.05555556  0.05555556  0.05555556  0.05555556  0.05555556\n",
      "   0.05555556  0.05555556  0.05555556  0.05555556  0.05555556  0.05555556]] \n",
      "Labels:  [[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.]\n",
      " [ 1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]]\n",
      "Ran Batch  2  out of  17 \n",
      "Results:  [[ 0.05555556  0.05555556  0.05555556  0.05555556  0.05555556  0.05555556\n",
      "   0.05555556  0.05555556  0.05555556  0.05555556  0.05555556  0.05555556\n",
      "   0.05555556  0.05555556  0.05555556  0.05555556  0.05555556  0.05555556]\n",
      " [ 0.05555556  0.05555556  0.05555556  0.05555556  0.05555556  0.05555556\n",
      "   0.05555556  0.05555556  0.05555556  0.05555556  0.05555556  0.05555556\n",
      "   0.05555556  0.05555556  0.05555556  0.05555556  0.05555556  0.05555556]\n",
      " [ 0.05555556  0.05555556  0.05555556  0.05555556  0.05555556  0.05555556\n",
      "   0.05555556  0.05555556  0.05555556  0.05555556  0.05555556  0.05555556\n",
      "   0.05555556  0.05555556  0.05555556  0.05555556  0.05555556  0.05555556]] \n",
      "Labels:  [[ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.]]\n",
      "Ran Batch  3  out of  17 \n",
      "Results:  [[ 0.05555556  0.05555556  0.05555556  0.05555556  0.05555556  0.05555556\n",
      "   0.05555556  0.05555556  0.05555556  0.05555556  0.05555556  0.05555556\n",
      "   0.05555556  0.05555556  0.05555556  0.05555556  0.05555556  0.05555556]\n",
      " [ 0.05555556  0.05555556  0.05555556  0.05555556  0.05555556  0.05555556\n",
      "   0.05555556  0.05555556  0.05555556  0.05555556  0.05555556  0.05555556\n",
      "   0.05555556  0.05555556  0.05555556  0.05555556  0.05555556  0.05555556]\n",
      " [ 0.05555556  0.05555556  0.05555556  0.05555556  0.05555556  0.05555556\n",
      "   0.05555556  0.05555556  0.05555556  0.05555556  0.05555556  0.05555556\n",
      "   0.05555556  0.05555556  0.05555556  0.05555556  0.05555556  0.05555556]] \n",
      "Labels:  [[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.]]\n",
      "Ran Batch  4  out of  17 \n",
      "Results:  [[ 0.05555556  0.05555556  0.05555556  0.05555556  0.05555556  0.05555556\n",
      "   0.05555556  0.05555556  0.05555556  0.05555556  0.05555556  0.05555556\n",
      "   0.05555556  0.05555556  0.05555556  0.05555556  0.05555556  0.05555556]\n",
      " [ 0.05555556  0.05555556  0.05555556  0.05555556  0.05555556  0.05555556\n",
      "   0.05555556  0.05555556  0.05555556  0.05555556  0.05555556  0.05555556\n",
      "   0.05555556  0.05555556  0.05555556  0.05555556  0.05555556  0.05555556]\n",
      " [ 0.05555556  0.05555556  0.05555556  0.05555556  0.05555556  0.05555556\n",
      "   0.05555556  0.05555556  0.05555556  0.05555556  0.05555556  0.05555556\n",
      "   0.05555556  0.05555556  0.05555556  0.05555556  0.05555556  0.05555556]] \n",
      "Labels:  [[ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.]]\n",
      "Ran Batch  5  out of  17 \n",
      "Results:  [[ 0.05555556  0.05555556  0.05555556  0.05555556  0.05555556  0.05555556\n",
      "   0.05555556  0.05555556  0.05555556  0.05555556  0.05555556  0.05555556\n",
      "   0.05555556  0.05555556  0.05555556  0.05555556  0.05555556  0.05555556]\n",
      " [ 0.05555556  0.05555556  0.05555556  0.05555556  0.05555556  0.05555556\n",
      "   0.05555556  0.05555556  0.05555556  0.05555556  0.05555556  0.05555556\n",
      "   0.05555556  0.05555556  0.05555556  0.05555556  0.05555556  0.05555556]\n",
      " [ 0.05555556  0.05555556  0.05555556  0.05555556  0.05555556  0.05555556\n",
      "   0.05555556  0.05555556  0.05555556  0.05555556  0.05555556  0.05555556\n",
      "   0.05555556  0.05555556  0.05555556  0.05555556  0.05555556  0.05555556]] \n",
      "Labels:  [[ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  0.]]\n",
      "Ran Batch  6  out of  17 \n",
      "Results:  [[ 0.05555556  0.05555556  0.05555556  0.05555556  0.05555556  0.05555556\n",
      "   0.05555556  0.05555556  0.05555556  0.05555556  0.05555556  0.05555556\n",
      "   0.05555556  0.05555556  0.05555556  0.05555556  0.05555556  0.05555556]\n",
      " [ 0.05555556  0.05555556  0.05555556  0.05555556  0.05555556  0.05555556\n",
      "   0.05555556  0.05555556  0.05555556  0.05555556  0.05555556  0.05555556\n",
      "   0.05555556  0.05555556  0.05555556  0.05555556  0.05555556  0.05555556]\n",
      " [ 0.05555556  0.05555556  0.05555556  0.05555556  0.05555556  0.05555556\n",
      "   0.05555556  0.05555556  0.05555556  0.05555556  0.05555556  0.05555556\n",
      "   0.05555556  0.05555556  0.05555556  0.05555556  0.05555556  0.05555556]] \n",
      "Labels:  [[ 1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.]]\n",
      "Ran Batch  7  out of  17 \n",
      "Results:  [[ 0.05555556  0.05555556  0.05555556  0.05555556  0.05555556  0.05555556\n",
      "   0.05555556  0.05555556  0.05555556  0.05555556  0.05555556  0.05555556\n",
      "   0.05555556  0.05555556  0.05555556  0.05555556  0.05555556  0.05555556]\n",
      " [ 0.05555556  0.05555556  0.05555556  0.05555556  0.05555556  0.05555556\n",
      "   0.05555556  0.05555556  0.05555556  0.05555556  0.05555556  0.05555556\n",
      "   0.05555556  0.05555556  0.05555556  0.05555556  0.05555556  0.05555556]\n",
      " [ 0.05555556  0.05555556  0.05555556  0.05555556  0.05555556  0.05555556\n",
      "   0.05555556  0.05555556  0.05555556  0.05555556  0.05555556  0.05555556\n",
      "   0.05555556  0.05555556  0.05555556  0.05555556  0.05555556  0.05555556]] \n",
      "Labels:  [[ 1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  1.  0.  1.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]]\n",
      "Ran Batch  8  out of  17 \n",
      "Results:  [[ 0.05555556  0.05555556  0.05555556  0.05555556  0.05555556  0.05555556\n",
      "   0.05555556  0.05555556  0.05555556  0.05555556  0.05555556  0.05555556\n",
      "   0.05555556  0.05555556  0.05555556  0.05555556  0.05555556  0.05555556]\n",
      " [ 0.05555556  0.05555556  0.05555556  0.05555556  0.05555556  0.05555556\n",
      "   0.05555556  0.05555556  0.05555556  0.05555556  0.05555556  0.05555556\n",
      "   0.05555556  0.05555556  0.05555556  0.05555556  0.05555556  0.05555556]\n",
      " [ 0.05555556  0.05555556  0.05555556  0.05555556  0.05555556  0.05555556\n",
      "   0.05555556  0.05555556  0.05555556  0.05555556  0.05555556  0.05555556\n",
      "   0.05555556  0.05555556  0.05555556  0.05555556  0.05555556  0.05555556]] \n",
      "Labels:  [[ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]]\n",
      "Ran Batch  9  out of  17 \n",
      "Results:  [[ 0.05555556  0.05555556  0.05555556  0.05555556  0.05555556  0.05555556\n",
      "   0.05555556  0.05555556  0.05555556  0.05555556  0.05555556  0.05555556\n",
      "   0.05555556  0.05555556  0.05555556  0.05555556  0.05555556  0.05555556]\n",
      " [ 0.05555556  0.05555556  0.05555556  0.05555556  0.05555556  0.05555556\n",
      "   0.05555556  0.05555556  0.05555556  0.05555556  0.05555556  0.05555556\n",
      "   0.05555556  0.05555556  0.05555556  0.05555556  0.05555556  0.05555556]\n",
      " [ 0.05555556  0.05555556  0.05555556  0.05555556  0.05555556  0.05555556\n",
      "   0.05555556  0.05555556  0.05555556  0.05555556  0.05555556  0.05555556\n",
      "   0.05555556  0.05555556  0.05555556  0.05555556  0.05555556  0.05555556]] \n",
      "Labels:  [[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.]\n",
      " [ 1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ran Batch  10  out of  17 \n",
      "Results:  [[ 0.05555556  0.05555556  0.05555556  0.05555556  0.05555556  0.05555556\n",
      "   0.05555556  0.05555556  0.05555556  0.05555556  0.05555556  0.05555556\n",
      "   0.05555556  0.05555556  0.05555556  0.05555556  0.05555556  0.05555556]\n",
      " [ 0.05555556  0.05555556  0.05555556  0.05555556  0.05555556  0.05555556\n",
      "   0.05555556  0.05555556  0.05555556  0.05555556  0.05555556  0.05555556\n",
      "   0.05555556  0.05555556  0.05555556  0.05555556  0.05555556  0.05555556]\n",
      " [ 0.05555556  0.05555556  0.05555556  0.05555556  0.05555556  0.05555556\n",
      "   0.05555556  0.05555556  0.05555556  0.05555556  0.05555556  0.05555556\n",
      "   0.05555556  0.05555556  0.05555556  0.05555556  0.05555556  0.05555556]] \n",
      "Labels:  [[ 1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.]]\n",
      "Ran Batch  11  out of  17 \n",
      "Results:  [[ 0.05555556  0.05555556  0.05555556  0.05555556  0.05555556  0.05555556\n",
      "   0.05555556  0.05555556  0.05555556  0.05555556  0.05555556  0.05555556\n",
      "   0.05555556  0.05555556  0.05555556  0.05555556  0.05555556  0.05555556]\n",
      " [ 0.05555556  0.05555556  0.05555556  0.05555556  0.05555556  0.05555556\n",
      "   0.05555556  0.05555556  0.05555556  0.05555556  0.05555556  0.05555556\n",
      "   0.05555556  0.05555556  0.05555556  0.05555556  0.05555556  0.05555556]\n",
      " [ 0.05555556  0.05555556  0.05555556  0.05555556  0.05555556  0.05555556\n",
      "   0.05555556  0.05555556  0.05555556  0.05555556  0.05555556  0.05555556\n",
      "   0.05555556  0.05555556  0.05555556  0.05555556  0.05555556  0.05555556]] \n",
      "Labels:  [[ 1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.]]\n",
      "Ran Batch  12  out of  17 \n",
      "Results:  [[ 0.05555556  0.05555556  0.05555556  0.05555556  0.05555556  0.05555556\n",
      "   0.05555556  0.05555556  0.05555556  0.05555556  0.05555556  0.05555556\n",
      "   0.05555556  0.05555556  0.05555556  0.05555556  0.05555556  0.05555556]\n",
      " [ 0.05555556  0.05555556  0.05555556  0.05555556  0.05555556  0.05555556\n",
      "   0.05555556  0.05555556  0.05555556  0.05555556  0.05555556  0.05555556\n",
      "   0.05555556  0.05555556  0.05555556  0.05555556  0.05555556  0.05555556]\n",
      " [ 0.05555556  0.05555556  0.05555556  0.05555556  0.05555556  0.05555556\n",
      "   0.05555556  0.05555556  0.05555556  0.05555556  0.05555556  0.05555556\n",
      "   0.05555556  0.05555556  0.05555556  0.05555556  0.05555556  0.05555556]] \n",
      "Labels:  [[ 0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.]\n",
      " [ 0.  0.  0.  1.  0.  1.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]]\n",
      "Ran Batch  13  out of  17 \n",
      "Results:  [[ 0.05555556  0.05555556  0.05555556  0.05555556  0.05555556  0.05555556\n",
      "   0.05555556  0.05555556  0.05555556  0.05555556  0.05555556  0.05555556\n",
      "   0.05555556  0.05555556  0.05555556  0.05555556  0.05555556  0.05555556]\n",
      " [ 0.05555556  0.05555556  0.05555556  0.05555556  0.05555556  0.05555556\n",
      "   0.05555556  0.05555556  0.05555556  0.05555556  0.05555556  0.05555556\n",
      "   0.05555556  0.05555556  0.05555556  0.05555556  0.05555556  0.05555556]\n",
      " [ 0.05555556  0.05555556  0.05555556  0.05555556  0.05555556  0.05555556\n",
      "   0.05555556  0.05555556  0.05555556  0.05555556  0.05555556  0.05555556\n",
      "   0.05555556  0.05555556  0.05555556  0.05555556  0.05555556  0.05555556]] \n",
      "Labels:  [[ 0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.]]\n",
      "Ran Batch  14  out of  17 \n",
      "Results:  [[ 0.05555556  0.05555556  0.05555556  0.05555556  0.05555556  0.05555556\n",
      "   0.05555556  0.05555556  0.05555556  0.05555556  0.05555556  0.05555556\n",
      "   0.05555556  0.05555556  0.05555556  0.05555556  0.05555556  0.05555556]\n",
      " [ 0.05555556  0.05555556  0.05555556  0.05555556  0.05555556  0.05555556\n",
      "   0.05555556  0.05555556  0.05555556  0.05555556  0.05555556  0.05555556\n",
      "   0.05555556  0.05555556  0.05555556  0.05555556  0.05555556  0.05555556]\n",
      " [ 0.05555556  0.05555556  0.05555556  0.05555556  0.05555556  0.05555556\n",
      "   0.05555556  0.05555556  0.05555556  0.05555556  0.05555556  0.05555556\n",
      "   0.05555556  0.05555556  0.05555556  0.05555556  0.05555556  0.05555556]] \n",
      "Labels:  [[ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  0.  0.  1.]]\n",
      "Ran Batch  15  out of  17 \n",
      "Results:  [[ 0.05555556  0.05555556  0.05555556  0.05555556  0.05555556  0.05555556\n",
      "   0.05555556  0.05555556  0.05555556  0.05555556  0.05555556  0.05555556\n",
      "   0.05555556  0.05555556  0.05555556  0.05555556  0.05555556  0.05555556]\n",
      " [ 0.05555556  0.05555556  0.05555556  0.05555556  0.05555556  0.05555556\n",
      "   0.05555556  0.05555556  0.05555556  0.05555556  0.05555556  0.05555556\n",
      "   0.05555556  0.05555556  0.05555556  0.05555556  0.05555556  0.05555556]\n",
      " [ 0.05555556  0.05555556  0.05555556  0.05555556  0.05555556  0.05555556\n",
      "   0.05555556  0.05555556  0.05555556  0.05555556  0.05555556  0.05555556\n",
      "   0.05555556  0.05555556  0.05555556  0.05555556  0.05555556  0.05555556]] \n",
      "Labels:  [[ 1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]]\n",
      "Ran Batch  16  out of  17 \n",
      "Results:  [[ 0.05555556  0.05555556  0.05555556  0.05555556  0.05555556  0.05555556\n",
      "   0.05555556  0.05555556  0.05555556  0.05555556  0.05555556  0.05555556\n",
      "   0.05555556  0.05555556  0.05555556  0.05555556  0.05555556  0.05555556]\n",
      " [ 0.05555556  0.05555556  0.05555556  0.05555556  0.05555556  0.05555556\n",
      "   0.05555556  0.05555556  0.05555556  0.05555556  0.05555556  0.05555556\n",
      "   0.05555556  0.05555556  0.05555556  0.05555556  0.05555556  0.05555556]] \n",
      "Labels:  [[ 0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "batch_size = 3       # num samples to validate per batch (this seems to be the max the card can handle at at time?)\n",
    "\n",
    "\n",
    "model_name = \"VGG_12-08-v2\"\n",
    "checkpoint_num = \"0\" # **** If not valid, will wipe old model!!! ****\n",
    "\n",
    "\n",
    "saver = tf.train.Saver()\n",
    "# setup the initialisation operator\n",
    "init_op = tf.global_variables_initializer()\n",
    "\n",
    "path = \"D:\\\\ML\\\\chkpts\\\\\"\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    \n",
    "    if os.path.exists(path+model_name) and os.path.exists(path+model_name+\"\\\\checkpoint_\"+checkpoint_num+\".ckpt.meta\"):\n",
    "        saver.restore(sess, path+model_name+\"\\\\checkpoint_\"+checkpoint_num+\".ckpt\")\n",
    "    else:\n",
    "        print(\"Invalid model checkpoint to validate\")\n",
    "        sys.exit()\n",
    "    \n",
    "    n = len(y_train)\n",
    "    batches = math.ceil(n / batch_size)\n",
    "    \n",
    "#     correct_preds = 0\n",
    "    for i in range(batches):\n",
    "        s = i * batch_size # start\n",
    "        e = min((i+1) * batch_size, n)\n",
    "        x_to_run = X_train[s:e]\n",
    "        y_to_run = y_train[s:e]\n",
    "        preds = sess.run(y_, feed_dict={x: x_to_run, y: y_to_run})\n",
    "#         correct_preds += int(round(test_acc * (e - s)))\n",
    "        print(\"Ran Batch \",i,\" out of \",batches,\"\\nResults: \",preds, \"\\nLabels: \",y_train[s:e])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# configconfig = tf.ConfigProto()\n",
    "# configconfig.log_device_placement = True\n",
    "# configconfig.gpu_options.allow_growth = True\n",
    "\n",
    "# config = tf.contrib.learn.RunConfig(session_config = configconfig)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
